apiVersion: v1
items:
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-10-05T18:36:53Z"
    labels:
      run: my-kafka-client
    name: my-kafka-client
    namespace: kafka
    resourceVersion: "194383"
    uid: 8b3a3416-2065-47be-86b2-2d0dc7033b7a
  spec:
    containers:
    - command:
      - sleep
      - infinity
      image: docker.io/bitnami/kafka:3.8.0-debian-12-r5
      imagePullPolicy: IfNotPresent
      name: my-kafka-client
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-24xvv
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: lw-cluster-worker
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Never
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-24xvv
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-10-05T18:37:21Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-10-05T18:36:57Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-10-05T18:37:21Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-10-05T18:37:21Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-10-05T18:36:55Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://370375a3f6a704df3e881a7f94e9389f46fda9cea4664e3ff3a39e9288113dda
      image: docker.io/bitnami/kafka:3.8.0-debian-12-r5
      imageID: docker.io/bitnami/kafka@sha256:999ba91863ef67e13c5704c3145154d0484671222dab2a603bfdeedc4a9fbad7
      lastState: {}
      name: my-kafka-client
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-10-05T18:37:18Z"
    hostIP: 172.18.0.2
    hostIPs:
    - ip: 172.18.0.2
    phase: Running
    podIP: 10.244.1.4
    podIPs:
    - ip: 10.244.1.4
    qosClass: BestEffort
    startTime: "2024-10-05T18:36:57Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      checksum/configuration: d12bb8c69754e0faa074a731776c14c5608d906797e234069721cfa29dd00679
      checksum/passwords-secret: ac749447c6b55277a7fbf42b188343af3ad5bab683b19318f912ea6884f32f4d
    creationTimestamp: "2024-10-05T18:23:25Z"
    generateName: my-kafka-controller-
    labels:
      app.kubernetes.io/component: controller-eligible
      app.kubernetes.io/instance: my-kafka
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: kafka
      app.kubernetes.io/part-of: kafka
      app.kubernetes.io/version: 3.8.0
      apps.kubernetes.io/pod-index: "0"
      controller-revision-hash: my-kafka-controller-78b75c9f57
      helm.sh/chart: kafka-30.1.4
      statefulset.kubernetes.io/pod-name: my-kafka-controller-0
    name: my-kafka-controller-0
    namespace: kafka
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: StatefulSet
      name: my-kafka-controller
      uid: da02ddfa-8df8-4160-8e6f-f5415ec84a2a
    resourceVersion: "193662"
    uid: e27da868-3d50-4134-9b35-42bcdb001a4a
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchLabels:
                app.kubernetes.io/component: controller-eligible
                app.kubernetes.io/instance: my-kafka
                app.kubernetes.io/name: kafka
            topologyKey: kubernetes.io/hostname
          weight: 1
    automountServiceAccountToken: true
    containers:
    - env:
      - name: BITNAMI_DEBUG
        value: "false"
      - name: KAFKA_HEAP_OPTS
        value: -Xmx1024m -Xms1024m
      - name: KAFKA_KRAFT_CLUSTER_ID
        valueFrom:
          secretKeyRef:
            key: kraft-cluster-id
            name: my-kafka-kraft-cluster-id
      - name: KAFKA_KRAFT_BOOTSTRAP_SCRAM_USERS
        value: "true"
      - name: KAFKA_INTER_BROKER_USER
        value: inter_broker_user
      - name: KAFKA_INTER_BROKER_PASSWORD
        valueFrom:
          secretKeyRef:
            key: inter-broker-password
            name: my-kafka-user-passwords
      - name: KAFKA_CONTROLLER_USER
        value: controller_user
      - name: KAFKA_CONTROLLER_PASSWORD
        valueFrom:
          secretKeyRef:
            key: controller-password
            name: my-kafka-user-passwords
      image: docker.io/bitnami/kafka:3.8.0-debian-12-r5
      imagePullPolicy: IfNotPresent
      livenessProbe:
        exec:
          command:
          - pgrep
          - -f
          - kafka
        failureThreshold: 3
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: kafka
      ports:
      - containerPort: 9093
        name: controller
        protocol: TCP
      - containerPort: 9092
        name: client
        protocol: TCP
      - containerPort: 9094
        name: interbroker
        protocol: TCP
      - containerPort: 9095
        name: external
        protocol: TCP
      readinessProbe:
        failureThreshold: 6
        initialDelaySeconds: 5
        periodSeconds: 10
        successThreshold: 1
        tcpSocket:
          port: controller
        timeoutSeconds: 5
      resources:
        limits:
          cpu: 750m
          ephemeral-storage: 2Gi
          memory: 768Mi
        requests:
          cpu: 500m
          ephemeral-storage: 50Mi
          memory: 512Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
        runAsGroup: 1001
        runAsNonRoot: true
        runAsUser: 1001
        seLinuxOptions: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /bitnami/kafka
        name: data
      - mountPath: /opt/bitnami/kafka/logs
        name: logs
      - mountPath: /opt/bitnami/kafka/config/server.properties
        name: kafka-config
        subPath: server.properties
      - mountPath: /tmp
        name: tmp
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-mg4vc
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostname: my-kafka-controller-0
    initContainers:
    - command:
      - /scripts/auto-discovery.sh
      env:
      - name: MY_POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: AUTODISCOVERY_SERVICE_TYPE
        value: NodePort
      image: docker.io/bitnami/kubectl:1.31.1-debian-12-r2
      imagePullPolicy: IfNotPresent
      name: auto-discovery
      resources:
        limits:
          cpu: 150m
          ephemeral-storage: 2Gi
          memory: 192Mi
        requests:
          cpu: 100m
          ephemeral-storage: 50Mi
          memory: 128Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
        runAsGroup: 1001
        runAsNonRoot: true
        runAsUser: 1001
        seLinuxOptions: {}
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /scripts/auto-discovery.sh
        name: scripts
        subPath: auto-discovery.sh
      - mountPath: /shared
        name: kafka-autodiscovery-shared
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-mg4vc
        readOnly: true
    - args:
      - -ec
      - |
        /scripts/kafka-init.sh
      command:
      - /bin/bash
      env:
      - name: BITNAMI_DEBUG
        value: "false"
      - name: MY_POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: KAFKA_VOLUME_DIR
        value: /bitnami/kafka
      - name: KAFKA_MIN_ID
        value: "0"
      - name: EXTERNAL_ACCESS_ENABLED
        value: "true"
      - name: HOST_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.hostIP
      - name: EXTERNAL_ACCESS_HOST
        value: $(HOST_IP)
      - name: KAFKA_INTER_BROKER_USER
        value: inter_broker_user
      - name: KAFKA_INTER_BROKER_PASSWORD
        valueFrom:
          secretKeyRef:
            key: inter-broker-password
            name: my-kafka-user-passwords
      - name: KAFKA_CONTROLLER_USER
        value: controller_user
      - name: KAFKA_CONTROLLER_PASSWORD
        valueFrom:
          secretKeyRef:
            key: controller-password
            name: my-kafka-user-passwords
      image: docker.io/bitnami/kafka:3.8.0-debian-12-r5
      imagePullPolicy: IfNotPresent
      name: kafka-init
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
        runAsGroup: 1001
        runAsNonRoot: true
        runAsUser: 1001
        seLinuxOptions: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /bitnami/kafka
        name: data
      - mountPath: /config
        name: kafka-config
      - mountPath: /configmaps
        name: kafka-configmaps
      - mountPath: /secret-config
        name: kafka-secret-config
      - mountPath: /scripts
        name: scripts
      - mountPath: /tmp
        name: tmp
      - mountPath: /shared
        name: kafka-autodiscovery-shared
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-mg4vc
        readOnly: true
    nodeName: lw-cluster-worker
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 1001
      fsGroupChangePolicy: Always
      seccompProfile:
        type: RuntimeDefault
    serviceAccount: my-kafka
    serviceAccountName: my-kafka
    subdomain: my-kafka-controller-headless
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: data
      persistentVolumeClaim:
        claimName: data-my-kafka-controller-0
    - configMap:
        defaultMode: 420
        name: my-kafka-controller-configuration
      name: kafka-configmaps
    - emptyDir: {}
      name: kafka-secret-config
    - emptyDir: {}
      name: kafka-config
    - emptyDir: {}
      name: tmp
    - configMap:
        defaultMode: 493
        name: my-kafka-scripts
      name: scripts
    - emptyDir: {}
      name: kafka-autodiscovery-shared
    - emptyDir: {}
      name: logs
    - name: kube-api-access-mg4vc
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-10-05T18:23:47Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-10-05T18:24:10Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-10-05T18:25:41Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-10-05T18:25:41Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-10-05T18:23:26Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://243bdd6936f041b60c5e22577806d7a3effb3b2f4f192bfbd4533001738bc00d
      image: docker.io/bitnami/kafka:3.8.0-debian-12-r5
      imageID: docker.io/bitnami/kafka@sha256:999ba91863ef67e13c5704c3145154d0484671222dab2a603bfdeedc4a9fbad7
      lastState: {}
      name: kafka
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-10-05T18:24:15Z"
    hostIP: 172.18.0.2
    hostIPs:
    - ip: 172.18.0.2
    initContainerStatuses:
    - containerID: containerd://826fddad572036396ea790dc121b8bf63636a734089f1d4d36706afde4643751
      image: docker.io/bitnami/kubectl:1.31.1-debian-12-r2
      imageID: docker.io/bitnami/kubectl@sha256:da4a9868e20d941636087cb8624a4bb441f5249d69e8f3d27e53c7d4d280a5f3
      lastState: {}
      name: auto-discovery
      ready: true
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://826fddad572036396ea790dc121b8bf63636a734089f1d4d36706afde4643751
          exitCode: 0
          finishedAt: "2024-10-05T18:23:49Z"
          reason: Completed
          startedAt: "2024-10-05T18:23:45Z"
    - containerID: containerd://2266698e02f804b7802a1c4904ee48f6d702ecd55b19274bd5acedc07d08e2a7
      image: docker.io/bitnami/kafka:3.8.0-debian-12-r5
      imageID: docker.io/bitnami/kafka@sha256:999ba91863ef67e13c5704c3145154d0484671222dab2a603bfdeedc4a9fbad7
      lastState: {}
      name: kafka-init
      ready: true
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: containerd://2266698e02f804b7802a1c4904ee48f6d702ecd55b19274bd5acedc07d08e2a7
          exitCode: 0
          finishedAt: "2024-10-05T18:24:07Z"
          reason: Completed
          startedAt: "2024-10-05T18:24:01Z"
    phase: Running
    podIP: 10.244.1.3
    podIPs:
    - ip: 10.244.1.3
    qosClass: Burstable
    startTime: "2024-10-05T18:23:28Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-10-01T16:08:40Z"
    generateName: coredns-7db6d8ff4d-
    labels:
      k8s-app: kube-dns
      pod-template-hash: 7db6d8ff4d
    name: coredns-7db6d8ff4d-29plc
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: coredns-7db6d8ff4d
      uid: 83cfcab3-22bc-4690-ac3e-a83c07450fa3
    resourceVersion: "193403"
    uid: b3348b9e-0b6b-40fe-989c-1ddde8fd2587
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchExpressions:
              - key: k8s-app
                operator: In
                values:
                - kube-dns
            topologyKey: kubernetes.io/hostname
          weight: 100
    containers:
    - args:
      - -conf
      - /etc/coredns/Corefile
      image: registry.k8s.io/coredns/coredns:v1.11.1
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 5
        httpGet:
          path: /health
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 60
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: coredns
      ports:
      - containerPort: 53
        name: dns
        protocol: UDP
      - containerPort: 53
        name: dns-tcp
        protocol: TCP
      - containerPort: 9153
        name: metrics
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /ready
          port: 8181
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        limits:
          memory: 170Mi
        requests:
          cpu: 100m
          memory: 70Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          add:
          - NET_BIND_SERVICE
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/coredns
        name: config-volume
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-rbsh6
        readOnly: true
    dnsPolicy: Default
    enableServiceLinks: true
    nodeName: lw-cluster-control-plane
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: coredns
    serviceAccountName: coredns
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/control-plane
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        items:
        - key: Corefile
          path: Corefile
        name: coredns
      name: config-volume
    - name: kube-api-access-rbsh6
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-10-05T18:21:16Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-10-01T16:10:30Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-10-05T18:22:53Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-10-05T18:22:53Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-10-01T16:10:27Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://7f10ccaf76478405ae0e9d81a367b4146e3fda6adada3ab7e1583aa78080aeaf
      image: registry.k8s.io/coredns/coredns:v1.11.1
      imageID: sha256:cbb01a7bd410dc08ba382018ab909a674fb0e48687f0c00797ed5bc34fcc6bb4
      lastState:
        terminated:
          containerID: containerd://0d0417048a27306de9052b10f4392824110a1043b24b5d6dbf6bf9885144b1f5
          exitCode: 255
          finishedAt: "2024-10-05T18:17:53Z"
          reason: Unknown
          startedAt: "2024-10-05T12:34:07Z"
      name: coredns
      ready: true
      restartCount: 13
      started: true
      state:
        running:
          startedAt: "2024-10-05T18:21:13Z"
    hostIP: 172.18.0.3
    hostIPs:
    - ip: 172.18.0.3
    phase: Running
    podIP: 10.244.0.2
    podIPs:
    - ip: 10.244.0.2
    qosClass: Burstable
    startTime: "2024-10-01T16:10:30Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-10-01T16:08:37Z"
    generateName: coredns-7db6d8ff4d-
    labels:
      k8s-app: kube-dns
      pod-template-hash: 7db6d8ff4d
    name: coredns-7db6d8ff4d-rj7mn
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: coredns-7db6d8ff4d
      uid: 83cfcab3-22bc-4690-ac3e-a83c07450fa3
    resourceVersion: "193406"
    uid: e0ab0b36-8325-4b66-ad46-d296999731e7
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchExpressions:
              - key: k8s-app
                operator: In
                values:
                - kube-dns
            topologyKey: kubernetes.io/hostname
          weight: 100
    containers:
    - args:
      - -conf
      - /etc/coredns/Corefile
      image: registry.k8s.io/coredns/coredns:v1.11.1
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 5
        httpGet:
          path: /health
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 60
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: coredns
      ports:
      - containerPort: 53
        name: dns
        protocol: UDP
      - containerPort: 53
        name: dns-tcp
        protocol: TCP
      - containerPort: 9153
        name: metrics
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /ready
          port: 8181
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        limits:
          memory: 170Mi
        requests:
          cpu: 100m
          memory: 70Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          add:
          - NET_BIND_SERVICE
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/coredns
        name: config-volume
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-58w8s
        readOnly: true
    dnsPolicy: Default
    enableServiceLinks: true
    nodeName: lw-cluster-control-plane
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: coredns
    serviceAccountName: coredns
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/control-plane
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        items:
        - key: Corefile
          path: Corefile
        name: coredns
      name: config-volume
    - name: kube-api-access-58w8s
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-10-05T18:21:19Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-10-01T16:10:28Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-10-05T18:22:54Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-10-05T18:22:54Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-10-01T16:10:27Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://1de79fb992add6ff7870e540dc4ef2eb41ecc1cf222cc1063d43f8a2fbac50ab
      image: registry.k8s.io/coredns/coredns:v1.11.1
      imageID: sha256:cbb01a7bd410dc08ba382018ab909a674fb0e48687f0c00797ed5bc34fcc6bb4
      lastState:
        terminated:
          containerID: containerd://958295db02e6071ab37db9dd3d176c42b03128f9689c2415ce1aa7e662e53ea7
          exitCode: 255
          finishedAt: "2024-10-05T18:17:53Z"
          reason: Unknown
          startedAt: "2024-10-05T12:35:03Z"
      name: coredns
      ready: true
      restartCount: 13
      started: true
      state:
        running:
          startedAt: "2024-10-05T18:21:16Z"
    hostIP: 172.18.0.3
    hostIPs:
    - ip: 172.18.0.3
    phase: Running
    podIP: 10.244.0.4
    podIPs:
    - ip: 10.244.0.4
    qosClass: Burstable
    startTime: "2024-10-01T16:10:28Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubeadm.kubernetes.io/etcd.advertise-client-urls: https://172.18.0.3:2379
      kubernetes.io/config.hash: 14366e2ebbcb8fa9f35e06e7c126934c
      kubernetes.io/config.mirror: 14366e2ebbcb8fa9f35e06e7c126934c
      kubernetes.io/config.seen: "2024-10-05T18:17:55.781724665Z"
      kubernetes.io/config.source: file
    creationTimestamp: "2024-10-05T18:19:47Z"
    labels:
      component: etcd
      tier: control-plane
    name: etcd-lw-cluster-control-plane
    namespace: kube-system
    ownerReferences:
    - apiVersion: v1
      controller: true
      kind: Node
      name: lw-cluster-control-plane
      uid: 3eef6300-a6b6-4412-835c-4a1d3ed75611
    resourceVersion: "193133"
    uid: 61929968-9eaf-44fb-8de1-b6a7632ac423
  spec:
    containers:
    - command:
      - etcd
      - --advertise-client-urls=https://172.18.0.3:2379
      - --cert-file=/etc/kubernetes/pki/etcd/server.crt
      - --client-cert-auth=true
      - --data-dir=/var/lib/etcd
      - --experimental-initial-corrupt-check=true
      - --experimental-watch-progress-notify-interval=5s
      - --initial-advertise-peer-urls=https://172.18.0.3:2380
      - --initial-cluster=lw-cluster-control-plane=https://172.18.0.3:2380
      - --key-file=/etc/kubernetes/pki/etcd/server.key
      - --listen-client-urls=https://127.0.0.1:2379,https://172.18.0.3:2379
      - --listen-metrics-urls=http://127.0.0.1:2381
      - --listen-peer-urls=https://172.18.0.3:2380
      - --name=lw-cluster-control-plane
      - --peer-cert-file=/etc/kubernetes/pki/etcd/peer.crt
      - --peer-client-cert-auth=true
      - --peer-key-file=/etc/kubernetes/pki/etcd/peer.key
      - --peer-trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt
      - --snapshot-count=10000
      - --trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt
      image: registry.k8s.io/etcd:3.5.12-0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 8
        httpGet:
          host: 127.0.0.1
          path: /health?exclude=NOSPACE&serializable=true
          port: 2381
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      name: etcd
      resources:
        requests:
          cpu: 100m
          memory: 100Mi
      startupProbe:
        failureThreshold: 24
        httpGet:
          host: 127.0.0.1
          path: /health?serializable=false
          port: 2381
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/etcd
        name: etcd-data
      - mountPath: /etc/kubernetes/pki/etcd
        name: etcd-certs
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: lw-cluster-control-plane
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      seccompProfile:
        type: RuntimeDefault
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      operator: Exists
    volumes:
    - hostPath:
        path: /etc/kubernetes/pki/etcd
        type: DirectoryOrCreate
      name: etcd-certs
    - hostPath:
        path: /var/lib/etcd
        type: DirectoryOrCreate
      name: etcd-data
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-10-05T18:18:42Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-10-05T18:18:01Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-10-05T18:19:26Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-10-05T18:19:26Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-10-05T18:18:01Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://71e5b0926f687dab7fd99c752b4dc2612ce85973386a239edf9ca49120e42e69
      image: registry.k8s.io/etcd:3.5.12-0
      imageID: sha256:3861cfcd7c04ccac1f062788eca39487248527ef0c0cfd477a83d7691a75a899
      lastState: {}
      name: etcd
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-10-05T18:18:41Z"
    hostIP: 172.18.0.3
    hostIPs:
    - ip: 172.18.0.3
    phase: Running
    podIP: 172.18.0.3
    podIPs:
    - ip: 172.18.0.3
    qosClass: Burstable
    startTime: "2024-10-05T18:18:01Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-10-01T16:09:14Z"
    generateName: kindnet-
    labels:
      app: kindnet
      controller-revision-hash: 6cc7f5689
      k8s-app: kindnet
      pod-template-generation: "1"
      tier: node
    name: kindnet-4fmn8
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: kindnet
      uid: 4a725530-10d1-4e66-8062-9fb475469083
    resourceVersion: "193219"
    uid: 9d026a2f-ee7b-4bc7-bb9a-d0d283d9b664
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - lw-cluster-control-plane
    containers:
    - env:
      - name: HOST_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.hostIP
      - name: POD_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      - name: POD_SUBNET
        value: 10.244.0.0/16
      - name: CONTROL_PLANE_ENDPOINT
        value: lw-cluster-control-plane:6443
      image: docker.io/kindest/kindnetd:v20240202-8f1494ea
      imagePullPolicy: IfNotPresent
      name: kindnet-cni
      resources:
        limits:
          cpu: 100m
          memory: 50Mi
        requests:
          cpu: 100m
          memory: 50Mi
      securityContext:
        capabilities:
          add:
          - NET_RAW
          - NET_ADMIN
        privileged: false
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/cni/net.d
        name: cni-cfg
      - mountPath: /run/xtables.lock
        name: xtables-lock
      - mountPath: /lib/modules
        name: lib-modules
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-4m82q
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: lw-cluster-control-plane
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: kindnet
    serviceAccountName: kindnet
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - hostPath:
        path: /etc/cni/net.d
        type: ""
      name: cni-cfg
    - hostPath:
        path: /run/xtables.lock
        type: FileOrCreate
      name: xtables-lock
    - hostPath:
        path: /lib/modules
        type: ""
      name: lib-modules
    - name: kube-api-access-4m82q
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-10-05T18:21:07Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-10-01T16:09:20Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-10-05T18:21:07Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-10-05T18:21:07Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-10-01T16:09:18Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://e58672d85e1418f2c278ea2ed3067d10613b36ebb3055ae0e0b664fb2a3b9e6e
      image: docker.io/kindest/kindnetd:v20240202-8f1494ea
      imageID: sha256:4950bb10b3f87e8d4a8f772a0d8934625cac4ccfa3675fea34cad0dab83fd5a5
      lastState:
        terminated:
          containerID: containerd://6efba89637e14e533979d88bcb2641f5506cef140c320b9de5bb161bfd2a832d
          exitCode: 255
          finishedAt: "2024-10-05T18:17:52Z"
          reason: Unknown
          startedAt: "2024-10-05T12:34:06Z"
      name: kindnet-cni
      ready: true
      restartCount: 13
      started: true
      state:
        running:
          startedAt: "2024-10-05T18:21:04Z"
    hostIP: 172.18.0.3
    hostIPs:
    - ip: 172.18.0.3
    phase: Running
    podIP: 172.18.0.3
    podIPs:
    - ip: 172.18.0.3
    qosClass: Guaranteed
    startTime: "2024-10-01T16:09:20Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-10-01T16:10:33Z"
    generateName: kindnet-
    labels:
      app: kindnet
      controller-revision-hash: 6cc7f5689
      k8s-app: kindnet
      pod-template-generation: "1"
      tier: node
    name: kindnet-c5qg6
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: kindnet
      uid: 4a725530-10d1-4e66-8062-9fb475469083
    resourceVersion: "193152"
    uid: 214fd0ab-00ca-45d5-ae7a-85acb8057f1c
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - lw-cluster-worker
    containers:
    - env:
      - name: HOST_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.hostIP
      - name: POD_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      - name: POD_SUBNET
        value: 10.244.0.0/16
      - name: CONTROL_PLANE_ENDPOINT
        value: lw-cluster-control-plane:6443
      image: docker.io/kindest/kindnetd:v20240202-8f1494ea
      imagePullPolicy: IfNotPresent
      name: kindnet-cni
      resources:
        limits:
          cpu: 100m
          memory: 50Mi
        requests:
          cpu: 100m
          memory: 50Mi
      securityContext:
        capabilities:
          add:
          - NET_RAW
          - NET_ADMIN
        privileged: false
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/cni/net.d
        name: cni-cfg
      - mountPath: /run/xtables.lock
        name: xtables-lock
      - mountPath: /lib/modules
        name: lib-modules
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-qbkbf
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: lw-cluster-worker
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: kindnet
    serviceAccountName: kindnet
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - hostPath:
        path: /etc/cni/net.d
        type: ""
      name: cni-cfg
    - hostPath:
        path: /run/xtables.lock
        type: FileOrCreate
      name: xtables-lock
    - hostPath:
        path: /lib/modules
        type: ""
      name: lib-modules
    - name: kube-api-access-qbkbf
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-10-05T18:19:32Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-10-01T16:10:44Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-10-05T18:20:20Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-10-05T18:20:20Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-10-01T16:10:41Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://56adae9560f0e77bc6ac94ddf28cf0cf921c4e453d63693ee397b047d0f9d901
      image: docker.io/kindest/kindnetd:v20240202-8f1494ea
      imageID: sha256:4950bb10b3f87e8d4a8f772a0d8934625cac4ccfa3675fea34cad0dab83fd5a5
      lastState:
        terminated:
          containerID: containerd://334278b4f77ef38e10f9dbe986920852da597853aa358664f2261b889073fc41
          exitCode: 255
          finishedAt: "2024-10-05T18:17:51Z"
          reason: Unknown
          startedAt: "2024-10-05T12:33:56Z"
      name: kindnet-cni
      ready: true
      restartCount: 13
      started: true
      state:
        running:
          startedAt: "2024-10-05T18:20:17Z"
    hostIP: 172.18.0.2
    hostIPs:
    - ip: 172.18.0.2
    phase: Running
    podIP: 172.18.0.2
    podIPs:
    - ip: 172.18.0.2
    qosClass: Guaranteed
    startTime: "2024-10-01T16:10:44Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubeadm.kubernetes.io/kube-apiserver.advertise-address.endpoint: 172.18.0.3:6443
      kubernetes.io/config.hash: 8eea77d5ca99ed5b87fe3d23b1dfb87b
      kubernetes.io/config.mirror: 8eea77d5ca99ed5b87fe3d23b1dfb87b
      kubernetes.io/config.seen: "2024-10-05T18:17:55.781731738Z"
      kubernetes.io/config.source: file
    creationTimestamp: "2024-10-05T18:19:47Z"
    labels:
      component: kube-apiserver
      tier: control-plane
    name: kube-apiserver-lw-cluster-control-plane
    namespace: kube-system
    ownerReferences:
    - apiVersion: v1
      controller: true
      kind: Node
      name: lw-cluster-control-plane
      uid: 3eef6300-a6b6-4412-835c-4a1d3ed75611
    resourceVersion: "203531"
    uid: 4f39f0eb-d71d-4f93-96ea-00fbddda26f0
  spec:
    containers:
    - command:
      - kube-apiserver
      - --advertise-address=172.18.0.3
      - --allow-privileged=true
      - --authorization-mode=Node,RBAC
      - --client-ca-file=/etc/kubernetes/pki/ca.crt
      - --enable-admission-plugins=NodeRestriction
      - --enable-bootstrap-token-auth=true
      - --etcd-cafile=/etc/kubernetes/pki/etcd/ca.crt
      - --etcd-certfile=/etc/kubernetes/pki/apiserver-etcd-client.crt
      - --etcd-keyfile=/etc/kubernetes/pki/apiserver-etcd-client.key
      - --etcd-servers=https://127.0.0.1:2379
      - --kubelet-client-certificate=/etc/kubernetes/pki/apiserver-kubelet-client.crt
      - --kubelet-client-key=/etc/kubernetes/pki/apiserver-kubelet-client.key
      - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
      - --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.crt
      - --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client.key
      - --requestheader-allowed-names=front-proxy-client
      - --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt
      - --requestheader-extra-headers-prefix=X-Remote-Extra-
      - --requestheader-group-headers=X-Remote-Group
      - --requestheader-username-headers=X-Remote-User
      - --runtime-config=
      - --secure-port=6443
      - --service-account-issuer=https://kubernetes.default.svc.cluster.local
      - --service-account-key-file=/etc/kubernetes/pki/sa.pub
      - --service-account-signing-key-file=/etc/kubernetes/pki/sa.key
      - --service-cluster-ip-range=10.96.0.0/16
      - --tls-cert-file=/etc/kubernetes/pki/apiserver.crt
      - --tls-private-key-file=/etc/kubernetes/pki/apiserver.key
      image: registry.k8s.io/kube-apiserver:v1.30.0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 8
        httpGet:
          host: 172.18.0.3
          path: /livez
          port: 6443
          scheme: HTTPS
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      name: kube-apiserver
      readinessProbe:
        failureThreshold: 3
        httpGet:
          host: 172.18.0.3
          path: /readyz
          port: 6443
          scheme: HTTPS
        periodSeconds: 1
        successThreshold: 1
        timeoutSeconds: 15
      resources:
        requests:
          cpu: 250m
      startupProbe:
        failureThreshold: 24
        httpGet:
          host: 172.18.0.3
          path: /livez
          port: 6443
          scheme: HTTPS
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/ssl/certs
        name: ca-certs
        readOnly: true
      - mountPath: /etc/ca-certificates
        name: etc-ca-certificates
        readOnly: true
      - mountPath: /etc/kubernetes/pki
        name: k8s-certs
        readOnly: true
      - mountPath: /usr/local/share/ca-certificates
        name: usr-local-share-ca-certificates
        readOnly: true
      - mountPath: /usr/share/ca-certificates
        name: usr-share-ca-certificates
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: lw-cluster-control-plane
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      seccompProfile:
        type: RuntimeDefault
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      operator: Exists
    volumes:
    - hostPath:
        path: /etc/ssl/certs
        type: DirectoryOrCreate
      name: ca-certs
    - hostPath:
        path: /etc/ca-certificates
        type: DirectoryOrCreate
      name: etc-ca-certificates
    - hostPath:
        path: /etc/kubernetes/pki
        type: DirectoryOrCreate
      name: k8s-certs
    - hostPath:
        path: /usr/local/share/ca-certificates
        type: DirectoryOrCreate
      name: usr-local-share-ca-certificates
    - hostPath:
        path: /usr/share/ca-certificates
        type: DirectoryOrCreate
      name: usr-share-ca-certificates
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-10-05T18:18:41Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-10-05T18:18:01Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-10-05T21:07:05Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-10-05T21:07:05Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-10-05T18:18:01Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://74fc43eca042e57fb265e1940c30f36594dedac684117fdf518618f8b94e9470
      image: registry.k8s.io/kube-apiserver-amd64:v1.30.0
      imageID: docker.io/library/import-2024-05-13@sha256:d147453847b7c5b8c33045e54d6e0301edea08b5ae152e84b9b5cab377e20321
      lastState: {}
      name: kube-apiserver
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-10-05T18:18:40Z"
    hostIP: 172.18.0.3
    hostIPs:
    - ip: 172.18.0.3
    phase: Running
    podIP: 172.18.0.3
    podIPs:
    - ip: 172.18.0.3
    qosClass: Burstable
    startTime: "2024-10-05T18:18:01Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubernetes.io/config.hash: 628f7e83299ae303ba71c45fe2f67f2e
      kubernetes.io/config.mirror: 628f7e83299ae303ba71c45fe2f67f2e
      kubernetes.io/config.seen: "2024-10-01T16:07:47.884800972Z"
      kubernetes.io/config.source: file
    creationTimestamp: "2024-10-01T16:07:50Z"
    labels:
      component: kube-controller-manager
      tier: control-plane
    name: kube-controller-manager-lw-cluster-control-plane
    namespace: kube-system
    ownerReferences:
    - apiVersion: v1
      controller: true
      kind: Node
      name: lw-cluster-control-plane
      uid: 3eef6300-a6b6-4412-835c-4a1d3ed75611
    resourceVersion: "196997"
    uid: a2acdea3-b5b5-425f-8fe4-8669de11d398
  spec:
    containers:
    - command:
      - kube-controller-manager
      - --allocate-node-cidrs=true
      - --authentication-kubeconfig=/etc/kubernetes/controller-manager.conf
      - --authorization-kubeconfig=/etc/kubernetes/controller-manager.conf
      - --bind-address=127.0.0.1
      - --client-ca-file=/etc/kubernetes/pki/ca.crt
      - --cluster-cidr=10.244.0.0/16
      - --cluster-name=lw-cluster
      - --cluster-signing-cert-file=/etc/kubernetes/pki/ca.crt
      - --cluster-signing-key-file=/etc/kubernetes/pki/ca.key
      - --controllers=*,bootstrapsigner,tokencleaner
      - --enable-hostpath-provisioner=true
      - --kubeconfig=/etc/kubernetes/controller-manager.conf
      - --leader-elect=true
      - --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt
      - --root-ca-file=/etc/kubernetes/pki/ca.crt
      - --service-account-private-key-file=/etc/kubernetes/pki/sa.key
      - --service-cluster-ip-range=10.96.0.0/16
      - --use-service-account-credentials=true
      image: registry.k8s.io/kube-controller-manager:v1.30.0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 8
        httpGet:
          host: 127.0.0.1
          path: /healthz
          port: 10257
          scheme: HTTPS
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      name: kube-controller-manager
      resources:
        requests:
          cpu: 200m
      startupProbe:
        failureThreshold: 24
        httpGet:
          host: 127.0.0.1
          path: /healthz
          port: 10257
          scheme: HTTPS
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/ssl/certs
        name: ca-certs
        readOnly: true
      - mountPath: /etc/ca-certificates
        name: etc-ca-certificates
        readOnly: true
      - mountPath: /usr/libexec/kubernetes/kubelet-plugins/volume/exec
        name: flexvolume-dir
      - mountPath: /etc/kubernetes/pki
        name: k8s-certs
        readOnly: true
      - mountPath: /etc/kubernetes/controller-manager.conf
        name: kubeconfig
        readOnly: true
      - mountPath: /usr/local/share/ca-certificates
        name: usr-local-share-ca-certificates
        readOnly: true
      - mountPath: /usr/share/ca-certificates
        name: usr-share-ca-certificates
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: lw-cluster-control-plane
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      seccompProfile:
        type: RuntimeDefault
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      operator: Exists
    volumes:
    - hostPath:
        path: /etc/ssl/certs
        type: DirectoryOrCreate
      name: ca-certs
    - hostPath:
        path: /etc/ca-certificates
        type: DirectoryOrCreate
      name: etc-ca-certificates
    - hostPath:
        path: /usr/libexec/kubernetes/kubelet-plugins/volume/exec
        type: DirectoryOrCreate
      name: flexvolume-dir
    - hostPath:
        path: /etc/kubernetes/pki
        type: DirectoryOrCreate
      name: k8s-certs
    - hostPath:
        path: /etc/kubernetes/controller-manager.conf
        type: FileOrCreate
      name: kubeconfig
    - hostPath:
        path: /usr/local/share/ca-certificates
        type: DirectoryOrCreate
      name: usr-local-share-ca-certificates
    - hostPath:
        path: /usr/share/ca-certificates
        type: DirectoryOrCreate
      name: usr-share-ca-certificates
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-10-05T18:18:41Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-10-05T18:17:59Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-10-05T19:21:00Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-10-05T19:21:00Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-10-05T18:17:59Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://6dde184b2d9128f7922fb768148ba5885e698b4669b056e644837b1e5aa040e5
      image: registry.k8s.io/kube-controller-manager-amd64:v1.30.0
      imageID: docker.io/library/import-2024-05-13@sha256:9615dec64d132ce44d42c15d071da7477499ab2aa9a44ff073b8d85944949023
      lastState:
        terminated:
          containerID: containerd://f0013cdedb52d694637d878c531708d2483807171d6e3c89b013605bbc83bda2
          exitCode: 1
          finishedAt: "2024-10-05T19:20:27Z"
          reason: Error
          startedAt: "2024-10-05T18:22:08Z"
      name: kube-controller-manager
      ready: true
      restartCount: 26
      started: true
      state:
        running:
          startedAt: "2024-10-05T19:20:44Z"
    hostIP: 172.18.0.3
    hostIPs:
    - ip: 172.18.0.3
    phase: Running
    podIP: 172.18.0.3
    podIPs:
    - ip: 172.18.0.3
    qosClass: Burstable
    startTime: "2024-10-05T18:17:59Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-10-01T16:10:33Z"
    generateName: kube-proxy-
    labels:
      controller-revision-hash: 79cf874c65
      k8s-app: kube-proxy
      pod-template-generation: "1"
    name: kube-proxy-gtgxj
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: kube-proxy
      uid: 15406c77-1f3f-4729-9d84-edc4fa19de14
    resourceVersion: "193143"
    uid: 2b6c97be-4178-419a-acfc-7bea384896fe
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - lw-cluster-worker
    containers:
    - command:
      - /usr/local/bin/kube-proxy
      - --config=/var/lib/kube-proxy/config.conf
      - --hostname-override=$(NODE_NAME)
      env:
      - name: NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      image: registry.k8s.io/kube-proxy:v1.30.0
      imagePullPolicy: IfNotPresent
      name: kube-proxy
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/kube-proxy
        name: kube-proxy
      - mountPath: /run/xtables.lock
        name: xtables-lock
      - mountPath: /lib/modules
        name: lib-modules
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-bdw6p
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: lw-cluster-worker
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: kube-proxy
    serviceAccountName: kube-proxy
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: kube-proxy
      name: kube-proxy
    - hostPath:
        path: /run/xtables.lock
        type: FileOrCreate
      name: xtables-lock
    - hostPath:
        path: /lib/modules
        type: ""
      name: lib-modules
    - name: kube-api-access-bdw6p
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-10-05T18:19:35Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-10-01T16:10:44Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-10-05T18:20:14Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-10-05T18:20:14Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-10-01T16:10:41Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://45f7afa18b0e259641a22167917cd672cd6ff7e3753f87a3562d8a53547d18e5
      image: registry.k8s.io/kube-proxy-amd64:v1.30.0
      imageID: docker.io/library/import-2024-05-13@sha256:98e54aaf0614547ead5c0bd7df946f6eb58f0abf0386240df20565d9dd2a2e8d
      lastState:
        terminated:
          containerID: containerd://8a10e23920ee55e1ed3b36f36ef438c9f26173f65ad64f259acf17b7d29e8887
          exitCode: 255
          finishedAt: "2024-10-05T18:17:51Z"
          reason: Unknown
          startedAt: "2024-10-05T12:33:54Z"
      name: kube-proxy
      ready: true
      restartCount: 13
      started: true
      state:
        running:
          startedAt: "2024-10-05T18:20:11Z"
    hostIP: 172.18.0.2
    hostIPs:
    - ip: 172.18.0.2
    phase: Running
    podIP: 172.18.0.2
    podIPs:
    - ip: 172.18.0.2
    qosClass: BestEffort
    startTime: "2024-10-01T16:10:44Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-10-01T16:08:35Z"
    generateName: kube-proxy-
    labels:
      controller-revision-hash: 79cf874c65
      k8s-app: kube-proxy
      pod-template-generation: "1"
    name: kube-proxy-zhq8t
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: kube-proxy
      uid: 15406c77-1f3f-4729-9d84-edc4fa19de14
    resourceVersion: "193179"
    uid: 9085714f-da30-4cf7-a330-d7991afb8fca
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - lw-cluster-control-plane
    containers:
    - command:
      - /usr/local/bin/kube-proxy
      - --config=/var/lib/kube-proxy/config.conf
      - --hostname-override=$(NODE_NAME)
      env:
      - name: NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      image: registry.k8s.io/kube-proxy:v1.30.0
      imagePullPolicy: IfNotPresent
      name: kube-proxy
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/kube-proxy
        name: kube-proxy
      - mountPath: /run/xtables.lock
        name: xtables-lock
      - mountPath: /lib/modules
        name: lib-modules
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-l575v
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: lw-cluster-control-plane
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: kube-proxy
    serviceAccountName: kube-proxy
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: kube-proxy
      name: kube-proxy
    - hostPath:
        path: /run/xtables.lock
        type: FileOrCreate
      name: xtables-lock
    - hostPath:
        path: /lib/modules
        type: ""
      name: lib-modules
    - name: kube-api-access-l575v
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-10-05T18:20:41Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-10-01T16:08:40Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-10-05T18:20:41Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-10-05T18:20:41Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-10-01T16:08:37Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://64ebfb787ca63d8bd0e5cef45f68f3389c01dd1a36ac7fad0de7ba42b7d13e2b
      image: registry.k8s.io/kube-proxy-amd64:v1.30.0
      imageID: docker.io/library/import-2024-05-13@sha256:98e54aaf0614547ead5c0bd7df946f6eb58f0abf0386240df20565d9dd2a2e8d
      lastState:
        terminated:
          containerID: containerd://aee30a4eb5206158a0f4e2f822f413a0cb6f225beb8b1d0ef244cc6240a85d90
          exitCode: 255
          finishedAt: "2024-10-05T18:17:53Z"
          reason: Unknown
          startedAt: "2024-10-05T12:34:05Z"
      name: kube-proxy
      ready: true
      restartCount: 13
      started: true
      state:
        running:
          startedAt: "2024-10-05T18:20:37Z"
    hostIP: 172.18.0.3
    hostIPs:
    - ip: 172.18.0.3
    phase: Running
    podIP: 172.18.0.3
    podIPs:
    - ip: 172.18.0.3
    qosClass: BestEffort
    startTime: "2024-10-01T16:08:40Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubernetes.io/config.hash: e8bf1a37d38620aed1108aa1e80e4f72
      kubernetes.io/config.mirror: e8bf1a37d38620aed1108aa1e80e4f72
      kubernetes.io/config.seen: "2024-10-01T16:07:47.884802375Z"
      kubernetes.io/config.source: file
    creationTimestamp: "2024-10-01T16:07:50Z"
    labels:
      component: kube-scheduler
      tier: control-plane
    name: kube-scheduler-lw-cluster-control-plane
    namespace: kube-system
    ownerReferences:
    - apiVersion: v1
      controller: true
      kind: Node
      name: lw-cluster-control-plane
      uid: 3eef6300-a6b6-4412-835c-4a1d3ed75611
    resourceVersion: "193122"
    uid: 2ad4ae3f-174b-4840-9a7c-b5e162707806
  spec:
    containers:
    - command:
      - kube-scheduler
      - --authentication-kubeconfig=/etc/kubernetes/scheduler.conf
      - --authorization-kubeconfig=/etc/kubernetes/scheduler.conf
      - --bind-address=127.0.0.1
      - --kubeconfig=/etc/kubernetes/scheduler.conf
      - --leader-elect=true
      image: registry.k8s.io/kube-scheduler:v1.30.0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 8
        httpGet:
          host: 127.0.0.1
          path: /healthz
          port: 10259
          scheme: HTTPS
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      name: kube-scheduler
      resources:
        requests:
          cpu: 100m
      startupProbe:
        failureThreshold: 24
        httpGet:
          host: 127.0.0.1
          path: /healthz
          port: 10259
          scheme: HTTPS
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/kubernetes/scheduler.conf
        name: kubeconfig
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: lw-cluster-control-plane
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      seccompProfile:
        type: RuntimeDefault
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      operator: Exists
    volumes:
    - hostPath:
        path: /etc/kubernetes/scheduler.conf
        type: FileOrCreate
      name: kubeconfig
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-10-05T18:18:41Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-10-05T18:17:59Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-10-05T18:19:13Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-10-05T18:19:13Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-10-05T18:17:59Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://86e7706db4398a31aca7eea9f9a3fe392d5d3826df3a8eeea628e0d6a0027047
      image: registry.k8s.io/kube-scheduler-amd64:v1.30.0
      imageID: docker.io/library/import-2024-05-13@sha256:06e68f241fc2e56756800474858d7b359f7cf4da31eddae316a342059c20c274
      lastState:
        terminated:
          containerID: containerd://4687ad06829c42e3f55c062d5fecf3ef877aff149646357690c07aec2911730a
          exitCode: 255
          finishedAt: "2024-10-05T18:17:53Z"
          reason: Unknown
          startedAt: "2024-10-05T12:32:44Z"
      name: kube-scheduler
      ready: true
      restartCount: 20
      started: true
      state:
        running:
          startedAt: "2024-10-05T18:18:39Z"
    hostIP: 172.18.0.3
    hostIPs:
    - ip: 172.18.0.3
    phase: Running
    podIP: 172.18.0.3
    podIPs:
    - ip: 172.18.0.3
    qosClass: Burstable
    startTime: "2024-10-05T18:17:59Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-10-01T16:09:44Z"
    generateName: local-path-provisioner-988d74bc-
    labels:
      app: local-path-provisioner
      pod-template-hash: 988d74bc
    name: local-path-provisioner-988d74bc-mm597
    namespace: local-path-storage
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: local-path-provisioner-988d74bc
      uid: 0eb64f71-888f-46b0-b824-31d391918d36
    resourceVersion: "193378"
    uid: c6458817-1860-4600-a671-105f61420729
  spec:
    containers:
    - command:
      - local-path-provisioner
      - --debug
      - start
      - --helper-image
      - docker.io/kindest/local-path-helper:v20230510-486859a6
      - --config
      - /etc/config/config.json
      env:
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: docker.io/kindest/local-path-provisioner:v20240202-8f1494ea
      imagePullPolicy: IfNotPresent
      name: local-path-provisioner
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/config/
        name: config-volume
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-rg4tf
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: lw-cluster-control-plane
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: local-path-provisioner-service-account
    serviceAccountName: local-path-provisioner-service-account
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/control-plane
      operator: Equal
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
      operator: Equal
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        name: local-path-config
      name: config-volume
    - name: kube-api-access-rg4tf
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-10-05T18:21:18Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-10-01T16:10:29Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-10-05T18:22:42Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-10-05T18:22:42Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-10-01T16:10:27Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: containerd://ebf8c41146ba7ed6014081100f52b04f19e324568a11a8338d7105c5fbb7ac30
      image: docker.io/kindest/local-path-provisioner:v20240202-8f1494ea
      imageID: sha256:0500518ebaa68d16973c65dc0b776813b50ab6e7e8f112fca41aca387a549d4f
      lastState:
        terminated:
          containerID: containerd://18e6136f3dff25704bdf42a3f469e65df6b9ebc80270ffb010382f60e54b4ef6
          exitCode: 1
          finishedAt: "2024-10-05T18:22:19Z"
          reason: Error
          startedAt: "2024-10-05T18:21:12Z"
      name: local-path-provisioner
      ready: true
      restartCount: 26
      started: true
      state:
        running:
          startedAt: "2024-10-05T18:22:41Z"
    hostIP: 172.18.0.3
    hostIPs:
    - ip: 172.18.0.3
    phase: Running
    podIP: 10.244.0.3
    podIPs:
    - ip: 10.244.0.3
    qosClass: BestEffort
    startTime: "2024-10-01T16:10:29Z"
- apiVersion: v1
  kind: Service
  metadata:
    creationTimestamp: "2024-10-01T16:07:37Z"
    labels:
      component: apiserver
      provider: kubernetes
    name: kubernetes
    namespace: default
    resourceVersion: "230"
    uid: bfc2e718-332e-4fa2-9545-54364baabcd5
  spec:
    clusterIP: 10.96.0.1
    clusterIPs:
    - 10.96.0.1
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: https
      port: 443
      protocol: TCP
      targetPort: 6443
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: my-kafka
      meta.helm.sh/release-namespace: kafka
    creationTimestamp: "2024-10-04T10:20:48Z"
    labels:
      app.kubernetes.io/component: kafka
      app.kubernetes.io/instance: my-kafka
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: kafka
      app.kubernetes.io/version: 3.8.0
      helm.sh/chart: kafka-30.1.4
    name: my-kafka
    namespace: kafka
    resourceVersion: "129645"
    uid: 64a6ee50-6bcf-4b61-a544-818996af5aec
  spec:
    clusterIP: 10.96.52.72
    clusterIPs:
    - 10.96.52.72
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: tcp-client
      port: 9092
      protocol: TCP
      targetPort: client
    - name: tcp-external
      port: 9095
      protocol: TCP
      targetPort: external
    selector:
      app.kubernetes.io/instance: my-kafka
      app.kubernetes.io/name: kafka
      app.kubernetes.io/part-of: kafka
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: my-kafka
      meta.helm.sh/release-namespace: kafka
    creationTimestamp: "2024-10-04T10:20:48Z"
    labels:
      app.kubernetes.io/component: kafka
      app.kubernetes.io/instance: my-kafka
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: kafka
      app.kubernetes.io/version: 3.8.0
      helm.sh/chart: kafka-30.1.4
      pod: my-kafka-controller-0
    name: my-kafka-controller-0-external
    namespace: kafka
    resourceVersion: "129650"
    uid: 939767e4-2901-4937-93c3-2fd1c6b52cb9
  spec:
    clusterIP: 10.96.127.235
    clusterIPs:
    - 10.96.127.235
    externalTrafficPolicy: Cluster
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: tcp-kafka
      nodePort: 31551
      port: 9094
      protocol: TCP
      targetPort: external
    selector:
      app.kubernetes.io/component: controller-eligible
      app.kubernetes.io/instance: my-kafka
      app.kubernetes.io/name: kafka
      app.kubernetes.io/part-of: kafka
      statefulset.kubernetes.io/pod-name: my-kafka-controller-0
    sessionAffinity: None
    type: NodePort
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: my-kafka
      meta.helm.sh/release-namespace: kafka
    creationTimestamp: "2024-10-04T10:20:48Z"
    labels:
      app.kubernetes.io/component: controller-eligible
      app.kubernetes.io/instance: my-kafka
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: kafka
      app.kubernetes.io/part-of: kafka
      app.kubernetes.io/version: 3.8.0
      helm.sh/chart: kafka-30.1.4
    name: my-kafka-controller-headless
    namespace: kafka
    resourceVersion: "129641"
    uid: 8f74a637-3379-4c3c-8e54-56289a360b68
  spec:
    clusterIP: None
    clusterIPs:
    - None
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: tcp-interbroker
      port: 9094
      protocol: TCP
      targetPort: interbroker
    - name: tcp-client
      port: 9092
      protocol: TCP
      targetPort: client
    - name: tcp-controller
      port: 9093
      protocol: TCP
      targetPort: controller
    publishNotReadyAddresses: true
    selector:
      app.kubernetes.io/component: controller-eligible
      app.kubernetes.io/instance: my-kafka
      app.kubernetes.io/name: kafka
      app.kubernetes.io/part-of: kafka
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      prometheus.io/port: "9153"
      prometheus.io/scrape: "true"
    creationTimestamp: "2024-10-01T16:07:49Z"
    labels:
      k8s-app: kube-dns
      kubernetes.io/cluster-service: "true"
      kubernetes.io/name: CoreDNS
    name: kube-dns
    namespace: kube-system
    resourceVersion: "296"
    uid: 01cd3406-c6db-4521-92bf-753864c67e2b
  spec:
    clusterIP: 10.96.0.10
    clusterIPs:
    - 10.96.0.10
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: dns
      port: 53
      protocol: UDP
      targetPort: 53
    - name: dns-tcp
      port: 53
      protocol: TCP
      targetPort: 53
    - name: metrics
      port: 9153
      protocol: TCP
      targetPort: 9153
    selector:
      k8s-app: kube-dns
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: apps/v1
  kind: DaemonSet
  metadata:
    annotations:
      deprecated.daemonset.template.generation: "1"
    creationTimestamp: "2024-10-01T16:09:07Z"
    generation: 1
    labels:
      app: kindnet
      k8s-app: kindnet
      tier: node
    name: kindnet
    namespace: kube-system
    resourceVersion: "167766"
    uid: 4a725530-10d1-4e66-8062-9fb475469083
  spec:
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: kindnet
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: kindnet
          k8s-app: kindnet
          tier: node
      spec:
        containers:
        - env:
          - name: HOST_IP
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: status.hostIP
          - name: POD_IP
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: status.podIP
          - name: POD_SUBNET
            value: 10.244.0.0/16
          - name: CONTROL_PLANE_ENDPOINT
            value: lw-cluster-control-plane:6443
          image: docker.io/kindest/kindnetd:v20240202-8f1494ea
          imagePullPolicy: IfNotPresent
          name: kindnet-cni
          resources:
            limits:
              cpu: 100m
              memory: 50Mi
            requests:
              cpu: 100m
              memory: 50Mi
          securityContext:
            capabilities:
              add:
              - NET_RAW
              - NET_ADMIN
            privileged: false
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/cni/net.d
            name: cni-cfg
          - mountPath: /run/xtables.lock
            name: xtables-lock
          - mountPath: /lib/modules
            name: lib-modules
            readOnly: true
        dnsPolicy: ClusterFirst
        hostNetwork: true
        nodeSelector:
          kubernetes.io/os: linux
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: kindnet
        serviceAccountName: kindnet
        terminationGracePeriodSeconds: 30
        tolerations:
        - operator: Exists
        volumes:
        - hostPath:
            path: /etc/cni/net.d
            type: ""
          name: cni-cfg
        - hostPath:
            path: /run/xtables.lock
            type: FileOrCreate
          name: xtables-lock
        - hostPath:
            path: /lib/modules
            type: ""
          name: lib-modules
    updateStrategy:
      rollingUpdate:
        maxSurge: 0
        maxUnavailable: 1
      type: RollingUpdate
  status:
    currentNumberScheduled: 2
    desiredNumberScheduled: 2
    numberAvailable: 2
    numberMisscheduled: 0
    numberReady: 2
    observedGeneration: 1
    updatedNumberScheduled: 2
- apiVersion: apps/v1
  kind: DaemonSet
  metadata:
    annotations:
      deprecated.daemonset.template.generation: "1"
    creationTimestamp: "2024-10-01T16:07:52Z"
    generation: 1
    labels:
      k8s-app: kube-proxy
    name: kube-proxy
    namespace: kube-system
    resourceVersion: "167760"
    uid: 15406c77-1f3f-4729-9d84-edc4fa19de14
  spec:
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        k8s-app: kube-proxy
    template:
      metadata:
        creationTimestamp: null
        labels:
          k8s-app: kube-proxy
      spec:
        containers:
        - command:
          - /usr/local/bin/kube-proxy
          - --config=/var/lib/kube-proxy/config.conf
          - --hostname-override=$(NODE_NAME)
          env:
          - name: NODE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
          image: registry.k8s.io/kube-proxy:v1.30.0
          imagePullPolicy: IfNotPresent
          name: kube-proxy
          resources: {}
          securityContext:
            privileged: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /var/lib/kube-proxy
            name: kube-proxy
          - mountPath: /run/xtables.lock
            name: xtables-lock
          - mountPath: /lib/modules
            name: lib-modules
            readOnly: true
        dnsPolicy: ClusterFirst
        hostNetwork: true
        nodeSelector:
          kubernetes.io/os: linux
        priorityClassName: system-node-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: kube-proxy
        serviceAccountName: kube-proxy
        terminationGracePeriodSeconds: 30
        tolerations:
        - operator: Exists
        volumes:
        - configMap:
            defaultMode: 420
            name: kube-proxy
          name: kube-proxy
        - hostPath:
            path: /run/xtables.lock
            type: FileOrCreate
          name: xtables-lock
        - hostPath:
            path: /lib/modules
            type: ""
          name: lib-modules
    updateStrategy:
      rollingUpdate:
        maxSurge: 0
        maxUnavailable: 1
      type: RollingUpdate
  status:
    currentNumberScheduled: 2
    desiredNumberScheduled: 2
    numberAvailable: 2
    numberMisscheduled: 0
    numberReady: 2
    observedGeneration: 1
    updatedNumberScheduled: 2
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2024-10-01T16:07:48Z"
    generation: 1
    labels:
      k8s-app: kube-dns
    name: coredns
    namespace: kube-system
    resourceVersion: "167895"
    uid: 9aefb2ae-9e83-4232-9af3-3f54e4f0fea1
  spec:
    progressDeadlineSeconds: 600
    replicas: 2
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        k8s-app: kube-dns
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 1
      type: RollingUpdate
    template:
      metadata:
        creationTimestamp: null
        labels:
          k8s-app: kube-dns
      spec:
        affinity:
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchExpressions:
                  - key: k8s-app
                    operator: In
                    values:
                    - kube-dns
                topologyKey: kubernetes.io/hostname
              weight: 100
        containers:
        - args:
          - -conf
          - /etc/coredns/Corefile
          image: registry.k8s.io/coredns/coredns:v1.11.1
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 5
            httpGet:
              path: /health
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          name: coredns
          ports:
          - containerPort: 53
            name: dns
            protocol: UDP
          - containerPort: 53
            name: dns-tcp
            protocol: TCP
          - containerPort: 9153
            name: metrics
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /ready
              port: 8181
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources:
            limits:
              memory: 170Mi
            requests:
              cpu: 100m
              memory: 70Mi
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              add:
              - NET_BIND_SERVICE
              drop:
              - ALL
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/coredns
            name: config-volume
            readOnly: true
        dnsPolicy: Default
        nodeSelector:
          kubernetes.io/os: linux
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: coredns
        serviceAccountName: coredns
        terminationGracePeriodSeconds: 30
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
        volumes:
        - configMap:
            defaultMode: 420
            items:
            - key: Corefile
              path: Corefile
            name: coredns
          name: config-volume
  status:
    availableReplicas: 2
    conditions:
    - lastTransitionTime: "2024-10-01T16:08:33Z"
      lastUpdateTime: "2024-10-01T16:13:30Z"
      message: ReplicaSet "coredns-7db6d8ff4d" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2024-10-05T12:34:55Z"
      lastUpdateTime: "2024-10-05T12:34:55Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 1
    readyReplicas: 2
    replicas: 2
    updatedReplicas: 2
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"name":"local-path-provisioner","namespace":"local-path-storage"},"spec":{"replicas":1,"selector":{"matchLabels":{"app":"local-path-provisioner"}},"template":{"metadata":{"labels":{"app":"local-path-provisioner"}},"spec":{"containers":[{"command":["local-path-provisioner","--debug","start","--helper-image","docker.io/kindest/local-path-helper:v20230510-486859a6","--config","/etc/config/config.json"],"env":[{"name":"POD_NAMESPACE","valueFrom":{"fieldRef":{"fieldPath":"metadata.namespace"}}}],"image":"docker.io/kindest/local-path-provisioner:v20240202-8f1494ea","imagePullPolicy":"IfNotPresent","name":"local-path-provisioner","volumeMounts":[{"mountPath":"/etc/config/","name":"config-volume"}]}],"nodeSelector":{"kubernetes.io/os":"linux"},"serviceAccountName":"local-path-provisioner-service-account","tolerations":[{"effect":"NoSchedule","key":"node-role.kubernetes.io/control-plane","operator":"Equal"},{"effect":"NoSchedule","key":"node-role.kubernetes.io/master","operator":"Equal"}],"volumes":[{"configMap":{"name":"local-path-config"},"name":"config-volume"}]}}}}
    creationTimestamp: "2024-10-01T16:09:33Z"
    generation: 1
    name: local-path-provisioner
    namespace: local-path-storage
    resourceVersion: "168107"
    uid: 63d2c32b-1b9f-4c52-8afa-f63803158734
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: local-path-provisioner
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: local-path-provisioner
      spec:
        containers:
        - command:
          - local-path-provisioner
          - --debug
          - start
          - --helper-image
          - docker.io/kindest/local-path-helper:v20230510-486859a6
          - --config
          - /etc/config/config.json
          env:
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: docker.io/kindest/local-path-provisioner:v20240202-8f1494ea
          imagePullPolicy: IfNotPresent
          name: local-path-provisioner
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/config/
            name: config-volume
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/os: linux
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: local-path-provisioner-service-account
        serviceAccountName: local-path-provisioner-service-account
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
          operator: Equal
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
          operator: Equal
        volumes:
        - configMap:
            defaultMode: 420
            name: local-path-config
          name: config-volume
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2024-10-01T16:09:35Z"
      lastUpdateTime: "2024-10-01T16:12:16Z"
      message: ReplicaSet "local-path-provisioner-988d74bc" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2024-10-05T12:37:29Z"
      lastUpdateTime: "2024-10-05T12:37:29Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "2"
      deployment.kubernetes.io/max-replicas: "3"
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2024-10-01T16:08:31Z"
    generation: 1
    labels:
      k8s-app: kube-dns
      pod-template-hash: 7db6d8ff4d
    name: coredns-7db6d8ff4d
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: coredns
      uid: 9aefb2ae-9e83-4232-9af3-3f54e4f0fea1
    resourceVersion: "167894"
    uid: 83cfcab3-22bc-4690-ac3e-a83c07450fa3
  spec:
    replicas: 2
    selector:
      matchLabels:
        k8s-app: kube-dns
        pod-template-hash: 7db6d8ff4d
    template:
      metadata:
        creationTimestamp: null
        labels:
          k8s-app: kube-dns
          pod-template-hash: 7db6d8ff4d
      spec:
        affinity:
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchExpressions:
                  - key: k8s-app
                    operator: In
                    values:
                    - kube-dns
                topologyKey: kubernetes.io/hostname
              weight: 100
        containers:
        - args:
          - -conf
          - /etc/coredns/Corefile
          image: registry.k8s.io/coredns/coredns:v1.11.1
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 5
            httpGet:
              path: /health
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          name: coredns
          ports:
          - containerPort: 53
            name: dns
            protocol: UDP
          - containerPort: 53
            name: dns-tcp
            protocol: TCP
          - containerPort: 9153
            name: metrics
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /ready
              port: 8181
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources:
            limits:
              memory: 170Mi
            requests:
              cpu: 100m
              memory: 70Mi
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              add:
              - NET_BIND_SERVICE
              drop:
              - ALL
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/coredns
            name: config-volume
            readOnly: true
        dnsPolicy: Default
        nodeSelector:
          kubernetes.io/os: linux
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: coredns
        serviceAccountName: coredns
        terminationGracePeriodSeconds: 30
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
        volumes:
        - configMap:
            defaultMode: 420
            items:
            - key: Corefile
              path: Corefile
            name: coredns
          name: config-volume
  status:
    availableReplicas: 2
    fullyLabeledReplicas: 2
    observedGeneration: 1
    readyReplicas: 2
    replicas: 2
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2024-10-01T16:09:34Z"
    generation: 1
    labels:
      app: local-path-provisioner
      pod-template-hash: 988d74bc
    name: local-path-provisioner-988d74bc
    namespace: local-path-storage
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: local-path-provisioner
      uid: 63d2c32b-1b9f-4c52-8afa-f63803158734
    resourceVersion: "168106"
    uid: 0eb64f71-888f-46b0-b824-31d391918d36
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: local-path-provisioner
        pod-template-hash: 988d74bc
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: local-path-provisioner
          pod-template-hash: 988d74bc
      spec:
        containers:
        - command:
          - local-path-provisioner
          - --debug
          - start
          - --helper-image
          - docker.io/kindest/local-path-helper:v20230510-486859a6
          - --config
          - /etc/config/config.json
          env:
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: docker.io/kindest/local-path-provisioner:v20240202-8f1494ea
          imagePullPolicy: IfNotPresent
          name: local-path-provisioner
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/config/
            name: config-volume
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/os: linux
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: local-path-provisioner-service-account
        serviceAccountName: local-path-provisioner-service-account
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
          operator: Equal
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
          operator: Equal
        volumes:
        - configMap:
            defaultMode: 420
            name: local-path-config
          name: config-volume
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: apps/v1
  kind: StatefulSet
  metadata:
    annotations:
      meta.helm.sh/release-name: my-kafka
      meta.helm.sh/release-namespace: kafka
    creationTimestamp: "2024-10-04T10:20:48Z"
    generation: 2
    labels:
      app.kubernetes.io/component: controller-eligible
      app.kubernetes.io/instance: my-kafka
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: kafka
      app.kubernetes.io/part-of: kafka
      app.kubernetes.io/version: 3.8.0
      helm.sh/chart: kafka-30.1.4
    name: my-kafka-controller
    namespace: kafka
    resourceVersion: "193670"
    uid: da02ddfa-8df8-4160-8e6f-f5415ec84a2a
  spec:
    persistentVolumeClaimRetentionPolicy:
      whenDeleted: Retain
      whenScaled: Retain
    podManagementPolicy: Parallel
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app.kubernetes.io/component: controller-eligible
        app.kubernetes.io/instance: my-kafka
        app.kubernetes.io/name: kafka
        app.kubernetes.io/part-of: kafka
    serviceName: my-kafka-controller-headless
    template:
      metadata:
        annotations:
          checksum/configuration: d12bb8c69754e0faa074a731776c14c5608d906797e234069721cfa29dd00679
          checksum/passwords-secret: ac749447c6b55277a7fbf42b188343af3ad5bab683b19318f912ea6884f32f4d
        creationTimestamp: null
        labels:
          app.kubernetes.io/component: controller-eligible
          app.kubernetes.io/instance: my-kafka
          app.kubernetes.io/managed-by: Helm
          app.kubernetes.io/name: kafka
          app.kubernetes.io/part-of: kafka
          app.kubernetes.io/version: 3.8.0
          helm.sh/chart: kafka-30.1.4
      spec:
        affinity:
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/component: controller-eligible
                    app.kubernetes.io/instance: my-kafka
                    app.kubernetes.io/name: kafka
                topologyKey: kubernetes.io/hostname
              weight: 1
        automountServiceAccountToken: true
        containers:
        - env:
          - name: BITNAMI_DEBUG
            value: "false"
          - name: KAFKA_HEAP_OPTS
            value: -Xmx1024m -Xms1024m
          - name: KAFKA_KRAFT_CLUSTER_ID
            valueFrom:
              secretKeyRef:
                key: kraft-cluster-id
                name: my-kafka-kraft-cluster-id
          - name: KAFKA_KRAFT_BOOTSTRAP_SCRAM_USERS
            value: "true"
          - name: KAFKA_INTER_BROKER_USER
            value: inter_broker_user
          - name: KAFKA_INTER_BROKER_PASSWORD
            valueFrom:
              secretKeyRef:
                key: inter-broker-password
                name: my-kafka-user-passwords
          - name: KAFKA_CONTROLLER_USER
            value: controller_user
          - name: KAFKA_CONTROLLER_PASSWORD
            valueFrom:
              secretKeyRef:
                key: controller-password
                name: my-kafka-user-passwords
          image: docker.io/bitnami/kafka:3.8.0-debian-12-r5
          imagePullPolicy: IfNotPresent
          livenessProbe:
            exec:
              command:
              - pgrep
              - -f
              - kafka
            failureThreshold: 3
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          name: kafka
          ports:
          - containerPort: 9093
            name: controller
            protocol: TCP
          - containerPort: 9092
            name: client
            protocol: TCP
          - containerPort: 9094
            name: interbroker
            protocol: TCP
          - containerPort: 9095
            name: external
            protocol: TCP
          readinessProbe:
            failureThreshold: 6
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            tcpSocket:
              port: controller
            timeoutSeconds: 5
          resources:
            limits:
              cpu: 750m
              ephemeral-storage: 2Gi
              memory: 768Mi
            requests:
              cpu: 500m
              ephemeral-storage: 50Mi
              memory: 512Mi
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seLinuxOptions: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /bitnami/kafka
            name: data
          - mountPath: /opt/bitnami/kafka/logs
            name: logs
          - mountPath: /opt/bitnami/kafka/config/server.properties
            name: kafka-config
            subPath: server.properties
          - mountPath: /tmp
            name: tmp
        dnsPolicy: ClusterFirst
        enableServiceLinks: true
        initContainers:
        - command:
          - /scripts/auto-discovery.sh
          env:
          - name: MY_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: AUTODISCOVERY_SERVICE_TYPE
            value: NodePort
          image: docker.io/bitnami/kubectl:1.31.1-debian-12-r2
          imagePullPolicy: IfNotPresent
          name: auto-discovery
          resources:
            limits:
              cpu: 150m
              ephemeral-storage: 2Gi
              memory: 192Mi
            requests:
              cpu: 100m
              ephemeral-storage: 50Mi
              memory: 128Mi
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seLinuxOptions: {}
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /scripts/auto-discovery.sh
            name: scripts
            subPath: auto-discovery.sh
          - mountPath: /shared
            name: kafka-autodiscovery-shared
        - args:
          - -ec
          - |
            /scripts/kafka-init.sh
          command:
          - /bin/bash
          env:
          - name: BITNAMI_DEBUG
            value: "false"
          - name: MY_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: KAFKA_VOLUME_DIR
            value: /bitnami/kafka
          - name: KAFKA_MIN_ID
            value: "0"
          - name: EXTERNAL_ACCESS_ENABLED
            value: "true"
          - name: HOST_IP
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: status.hostIP
          - name: EXTERNAL_ACCESS_HOST
            value: $(HOST_IP)
          - name: KAFKA_INTER_BROKER_USER
            value: inter_broker_user
          - name: KAFKA_INTER_BROKER_PASSWORD
            valueFrom:
              secretKeyRef:
                key: inter-broker-password
                name: my-kafka-user-passwords
          - name: KAFKA_CONTROLLER_USER
            value: controller_user
          - name: KAFKA_CONTROLLER_PASSWORD
            valueFrom:
              secretKeyRef:
                key: controller-password
                name: my-kafka-user-passwords
          image: docker.io/bitnami/kafka:3.8.0-debian-12-r5
          imagePullPolicy: IfNotPresent
          name: kafka-init
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seLinuxOptions: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /bitnami/kafka
            name: data
          - mountPath: /config
            name: kafka-config
          - mountPath: /configmaps
            name: kafka-configmaps
          - mountPath: /secret-config
            name: kafka-secret-config
          - mountPath: /scripts
            name: scripts
          - mountPath: /tmp
            name: tmp
          - mountPath: /shared
            name: kafka-autodiscovery-shared
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 1001
          fsGroupChangePolicy: Always
          seccompProfile:
            type: RuntimeDefault
        serviceAccount: my-kafka
        serviceAccountName: my-kafka
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 420
            name: my-kafka-controller-configuration
          name: kafka-configmaps
        - emptyDir: {}
          name: kafka-secret-config
        - emptyDir: {}
          name: kafka-config
        - emptyDir: {}
          name: tmp
        - configMap:
            defaultMode: 493
            name: my-kafka-scripts
          name: scripts
        - emptyDir: {}
          name: kafka-autodiscovery-shared
        - emptyDir: {}
          name: logs
    updateStrategy:
      type: RollingUpdate
    volumeClaimTemplates:
    - apiVersion: v1
      kind: PersistentVolumeClaim
      metadata:
        creationTimestamp: null
        name: data
      spec:
        accessModes:
        - ReadWriteOnce
        resources:
          requests:
            storage: 8Gi
        volumeMode: Filesystem
      status:
        phase: Pending
  status:
    availableReplicas: 1
    collisionCount: 0
    currentReplicas: 1
    currentRevision: my-kafka-controller-78b75c9f57
    observedGeneration: 2
    readyReplicas: 1
    replicas: 1
    updateRevision: my-kafka-controller-78b75c9f57
    updatedReplicas: 1
kind: List
metadata:
  resourceVersion: ""
